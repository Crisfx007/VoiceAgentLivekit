# ðŸŽ™ LiveKit Voice Onboarding Agent

## ðŸ“Œ Overview
This project is a **real-time voice onboarding assistant** built using [LiveKit](https://livekit.io/) and OpenAIâ€™s GPT-4o models.  
The agent interacts with users entirely in **voice** â€” introducing your service, collecting onboarding details, validating them, and confirming in real time.

It works just like a human onboarding agent:
- Welcomes the user.
- Asks for **Name, Email, Phone Number, and Country**.
- Validates inputs using **Pydantic**.
- Stores all onboarding data and the **entire conversation** in a per-session JSON file.
- Provides summaries and can re-ask for invalid inputs.
- All communication is in **voice** (both input and output).

---

## âš™ Tech Stack

### **Framework**
- **[LiveKit Agents SDK](https://github.com/livekit/agents)** â€” For real-time voice interaction, STT, TTS, and session management.

### **LLM (Language Model)**
- **OpenAI GPT-4o-mini** â€” For conversation flow, reasoning, and function/tool calling.

### **STT (Speech-to-Text)**
- **OpenAI `gpt-4o-transcribe`** â€” High accuracy real-time transcription.

### **TTS (Text-to-Speech)**
- **OpenAI `gpt-4o-mini-tts`** â€” Fast natural-sounding voice synthesis.

### **VAD (Voice Activity Detection)**
- **Silero VAD** â€” Detects when the user starts and stops speaking.

### **Turn Detection**
- **LiveKit Multilingual Turn Detector** â€” Ensures proper conversational turn-taking.

### **Validation & Data Storage**
- **Pydantic** â€” Strong form field validation for name, email, phone, and country.
- **pycountry** â€” For validating real country names.
- **JSON-based Session Storage** â€” Saves onboarding state and conversation logs.

---

## ðŸ“‚ Project Structure

- **agent.py** â€” Main agent setup and LiveKit session handling  
- **prompts.py** â€” Prompt instructions for onboarding flow  
- **tools.py** â€” Onboarding logic, validation, and JSON storage  
- **requirements.txt** â€” Python dependencies  
- **README.md** â€” This file  

---

## ðŸ”‘ Environment Variables

You must create a `.env` file in the root directory with:

```env
OPENAI_API_KEY=your_openai_api_key_here
LIVEKIT_URL=wss://your_livekit_server_url
LIVEKIT_API_KEY=your_livekit_api_key
LIVEKIT_API_SECRET=your_livekit_api_secret
Explanation:

OPENAI_API_KEY â€” Required for LLM, STT, and TTS models.

LIVEKIT_URL â€” WebSocket URL of your LiveKit deployment (e.g., wss://example.livekit.cloud).

LIVEKIT_API_KEY â€” API key for your LiveKit server.

LIVEKIT_API_SECRET â€” API secret for your LiveKit server.

ðŸ›  Tool Calling
The LLM uses LiveKit's function_tool decorators to call Python functions like:

validate_field(field, value) â€” Validate form input.

store_field(field, value) â€” Store validated input.

save_current_session() â€” Save the current session to JSON.

get_summary() â€” Return a summary of all collected onboarding data.

log_message(speaker, text) â€” Log conversation messages.

This means the LLM can directly call Python functions instead of just generating text.
